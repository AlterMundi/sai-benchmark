--- test_server2.py
+++ test_server2.py
@@ -64,6 +64,17 @@ class EvaluationMetrics(BaseModel):
     false_negatives: int
     total_processing_time: float
 
+class ModelInfo(BaseModel):
+    name: str
+    version: Optional[str]
+    type: Optional[str]
+    parameters: Optional[Dict]
+
+class DetailedResponse(BaseModel):
+    prompt: str
+    raw_output: str
+    parsing_success: bool
+
 class AnalysisResponse(BaseModel):
     metrics: EvaluationMetrics
     results: List[SequenceResult]
@@ -143,6 +154,10 @@ def calculate_metrics(results):
         recall=recall,
         f1_score=f1_score,
         total_sequences=total,
+        total_processing_time=total_processing_time,
+        true_positives=true_positives,
+        true_negatives=true_negatives,
+        false_positives=false_positives,
@@ -185,6 +200,17 @@ def get_sequence_info(dataset_path, sequence_folder):
     
     raise Exception(f"No image files found in sequence folder: {sequence_path}")
 
+# Function to get model information
+def get_model_info(model_name):
+    try:
+        model_details = ollama.show(model=model_name)
+        return ModelInfo(
+            name=model_name,
+            version=model_details.get("version", None),
+            type=model_details.get("modeltype", None),
+            parameters=model_details.get("parameters", None)
+        )
+    except Exception as e:
+        logger.error(f"Error getting model info: {str(e)}")
+        return ModelInfo(name=model_name)
+
 # Function to analyze a single sequence
 async def analyze_sequence(sequence_info, model, prompt):
     start_time = time.time()
@@ -210,20 +236,30 @@ async def analyze_sequence(sequence_info, model, prompt):
     # Call Ollama API with all images at once
     try:
         response = ollama.chat(model=model, messages=[message])
-        output = response["message"]["content"]
+        output = response.get("message", {}).get("content", "")
         
         print(output)
         # Parse the response
-        prediction, confidence, justification = parse_response(output)
+        try:
+            prediction, confidence, justification = parse_response(output)
+            parsing_success = True
+        except Exception as e:
+            logger.error(f"Error parsing response: {str(e)}")
+            prediction = False
+            confidence = 0.0
+            justification = f"Error parsing response: {str(e)}"
+            parsing_success = False
         
         processing_time = time.time() - start_time
         
         # Get sequence ID from folder path
         sequence_id = os.path.basename(sequence_info.folder_path)
         
+        # Create detailed response object
+        detailed_response = DetailedResponse(prompt=prompt, raw_output=output, parsing_success=parsing_success)
+        
         return SequenceResult(
             sequence_id=sequence_id,
@@ -233,6 +269,7 @@ async def analyze_sequence(sequence_info, model, prompt):
             justification=justification,
             processing_time=processing_time,
             raw_response=output,
+            detailed_response=detailed_response,
             is_correct=(prediction == sequence_info.ground_truth)
         )
     except Exception as e:
@@ -248,14 +285,19 @@ async def process_dataset(job_id, request: AnalysisRequest):
         
         logger.info(f"Starting job {job_id} to process dataset at {request.dataset_path}")
         
+        # Get model information
+        model_info = get_model_info(request.model)
+        active_jobs[job_id]["model_info"] = model_info.dict()
+        
         # Get sequence folders
         sequence_folders = get_sequence_folders(request.dataset_path, request.max_sequences)
         total_sequences = len(sequence_folders)
         
-        logger.info(f"Found {total_sequences} sequence folders")
+        logger.info(f"Found {total_sequences} sequence folders to process with model {request.model}")
         
         # Update job status
         active_jobs[job_id]["total"] = total_sequences
+        active_jobs[job_id]["responses"] = []
         
         # Use provided prompt or default
         prompt = request.prompt or DEFAULT_PROMPT
@@ -271,6 +313,13 @@ async def process_dataset(job_id, request: AnalysisRequest):
                 # Get sequence info
                 sequence_info = get_sequence_info(request.dataset_path, folder)
                 
+                # Log sequence details
+                logger.info(f"Processing sequence {folder} with {len(sequence_info.images)} images")
+                for img in sequence_info.images[:3]:  # Log first 3 images
+                    logger.info(f"  - Image: {img.filename}")
+                if len(sequence_info.images) > 3:
+                    logger.info(f"  - ...and {len(sequence_info.images) - 3} more images")
+                
                 # Analyze sequence
                 result = await analyze_sequence(sequence_info, request.model, prompt)
                 
@@ -278,12 +327,28 @@ async def process_dataset(job_id, request: AnalysisRequest):
                 
                 # Update job results
                 active_jobs[job_id]["results"] = results
+                active_jobs[job_id]["responses"].append({
+                    "sequence_id": result.sequence_id,
+                    "prompt": prompt,
+                    "raw_response": result.raw_response,
+                    "prediction": result.prediction,
+                    "confidence": result.confidence,
+                    "ground_truth": result.ground_truth,
+                    "is_correct": result.is_correct,
+                    "processing_time": result.processing_time
+                })
                 
-                logger.info(f"Completed sequence {folder}: Prediction={result.prediction}, Ground Truth={result.ground_truth}, Correct={result.is_correct}")
+                logger.info(f"Completed sequence {folder}: Prediction={result.prediction}, "
+                           f"Confidence={result.confidence}, Ground Truth={result.ground_truth}, "
+                           f"Correct={result.is_correct}, Time={result.processing_time:.2f}s")
                 
             except Exception as e:
                 logger.error(f"Error processing sequence {folder}: {str(e)}")
-                # Continue with next sequence
+                # Log the error in responses
+                active_jobs[job_id]["responses"].append({
+                    "sequence_id": folder,
+                    "error": str(e)
+                })
         
         # Calculate metrics
         metrics = calculate_metrics(results)
@@ -292,12 +357,21 @@ async def process_dataset(job_id, request: AnalysisRequest):
         timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
         results_file = f"results_{job_id}_{timestamp}.json"
         
+        # Prepare complete result data
+        result_data = {
+            "metrics": metrics.dict(),
+            "results": [r.dict() for r in results],
+            "model_info": active_jobs[job_id].get("model_info", {}),
+            "responses": active_jobs[job_id].get("responses", []),
+            "job_config": {
+                "dataset_path": request.dataset_path,
+                "model": request.model,
+                "max_sequences": request.max_sequences,
+                "prompt_used": prompt
+            }
+        }
+        
         with open(results_file, 'w') as f:
-            json.dump({
-                "metrics": metrics.dict(),
-                "results": [r.dict() for r in results]
-            }, f, indent=2)
+            json.dump(result_data, f, indent=2)
         
         logger.info(f"Completed job {job_id}. Results saved to {results_file}")
         logger.info(f"Metrics: Accuracy={metrics.accuracy:.4f}, Precision={metrics.precision:.4f}, Recall={metrics.recall:.4f}, F1={metrics.f1_score:.4f}")
@@ -305,10 +379,17 @@ async def process_dataset(job_id, request: AnalysisRequest):
         # Update job status
         active_jobs[job_id]["status"] = "completed"
         active_jobs[job_id]["metrics"] = metrics
+        active_jobs[job_id]["completed_at"] = datetime.now().isoformat()
+        active_jobs[job_id]["duration"] = time.time() - active_jobs[job_id]["start_time"]
         
     except Exception as e:
         logger.error(f"Error processing dataset: {str(e)}")
         active_jobs[job_id]["status"] = "failed"
+        active_jobs[job_id]["completed_at"] = datetime.now().isoformat()
+        active_jobs[job_id]["duration"] = time.time() - active_jobs[job_id]["start_time"]
+        active_jobs[job_id]["fatal_error"] = {
+            "message": str(e),
+            "traceback": traceback.format_exc()
+        }
         active_jobs[job_id]["error"] = str(e)
 
@@ -323,6 +404,9 @@ async def analyze_dataset(background_tasks: BackgroundTasks, request: AnalysisRe
         "request": request.dict(),
         "total": 0,
         "current": 0,
+        "responses": [],
+        "created_at": datetime.now().isoformat(),
+        "dataset_path": request.dataset_path,
         "results": [],
         "start_time": time.time()
     }
@@ -334,15 +418,29 @@ async def analyze_dataset(background_tasks: BackgroundTasks, request: AnalysisRe
 
 @app.get("/job/{job_id}")
 async def get_job_status(job_id: str):
+    include_responses = request.query_params.get("include_responses", "false").lower() == "true"
+    
     if job_id not in active_jobs:
         raise HTTPException(status_code=404, detail=f"Job not found: {job_id}")
     
     job = active_jobs[job_id]
     
     # Calculate progress
-    progress = (job["current"] / job["total"]) * 100 if job["total"] > 0 else 0
+    progress = round((job["current"] / job["total"]) * 100, 2) if job["total"] > 0 else 0
+    
+    # Calculate elapsed time and estimated time remaining
+    elapsed_time = time.time() - job["start_time"]
+    
+    # Calculate estimated remaining time if job is in progress
+    remaining_time = None
+    if job["status"] == "processing" and job["current"] > 0 and job["total"] > 0:
+        time_per_sequence = elapsed_time / job["current"]
+        sequences_remaining = job["total"] - job["current"]
+        remaining_time = time_per_sequence * sequences_remaining
+    
+    # Format times nicely
+    elapsed_time_str = str(datetime.timedelta(seconds=int(elapsed_time)))
+    remaining_time_str = str(datetime.timedelta(seconds=int(remaining_time))) if remaining_time is not None else None
     
-    # Calculate elapsed time
-    elapsed_time = time.time() - job["start_time"]
     
     response = {
         "job_id": job_id,
@@ -350,7 +448,15 @@ async def get_job_status(job_id: str):
         "progress": progress,
         "current": job["current"],
         "total": job["total"],
-        "elapsed_time": elapsed_time
+        "elapsed_time": elapsed_time,
+        "elapsed_time_formatted": elapsed_time_str,
+        "estimated_remaining": remaining_time,
+        "estimated_remaining_formatted": remaining_time_str,
+        "created_at": job.get("created_at"),
+        "completed_at": job.get("completed_at"),
+        "dataset_path": job.get("dataset_path"),
+        "model_info": job.get("model_info", {}),
+        "duration": job.get("duration")
     }
     
     # Include metrics if completed
@@ -359,6 +465,10 @@ async def get_job_status(job_id: str):
     
     # Include error if failed
     if job["status"] == "failed" and "error" in job:
+        response["error"] = job["error"]
+    
+    # Include detailed responses if requested
+    if include_responses and "responses" in job:
         response["error"] = job["error"]
     
     return response

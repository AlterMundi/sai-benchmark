# SAI - Arquitectura Completa del Sistema de DetecciÃ³n de Incendios

## ğŸ¯ **VISIÃ“N GENERAL**

El Sistema de Alerta de Incendios (SAI) implementa una arquitectura hÃ­brida de dos etapas para lograr detecciÃ³n temprana con mÃ¡xima precisiÃ³n y mÃ­nimos falsos positivos.

```
ğŸ”¥ FLUJO COMPLETO DEL SISTEMA SAI
=====================================

Imagen de Entrada (1440x808) 
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ETAPA A: DETECTOR        â”‚
â”‚    YOLOv8-s                 â”‚
â”‚    â€¢ Alto Recall            â”‚
â”‚    â€¢ DetecciÃ³n RÃ¡pida       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Bounding Boxes + Conf.
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ETAPA B: VERIFICADOR     â”‚  
â”‚    CNN SmokeyNet-Lite       â”‚
â”‚    â€¢ Reduce Falsos Positivosâ”‚
â”‚    â€¢ Confirma Detecciones   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   DecisiÃ³n Final: ALERTA/NO_ALERTA
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    SISTEMA DE NOTIFICACIÃ“N  â”‚
â”‚    â€¢ Telegram Bot           â”‚
â”‚    â€¢ Dashboard Web          â”‚
â”‚    â€¢ Logs de Eventos        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š **ESPECIFICACIONES TÃ‰CNICAS**

### **Hardware Recomendado**

#### **Servidor Central (Entrenamiento + Inferencia)**
- **GPU**: NVIDIA RTX 3090 (24GB VRAM) o A100 (40GB VRAM)
- **CPU**: AMD Ryzen 9 5900X o Intel i9-11900K
- **RAM**: 64GB DDR4
- **Storage**: 2TB NVMe SSD
- **Conectividad**: Gigabit Ethernet

#### **Nodos Edge (SAI-CAM)**
- **SBC**: Raspberry Pi 4B (8GB RAM) 
- **CÃ¡mara**: IP Camera 1080p con visiÃ³n nocturna
- **Storage**: 128GB microSD (Clase 10)
- **Conectividad**: WiFi 802.11ac / Ethernet
- **AlimentaciÃ³n**: PoE+ (25W) o fuente 5V/3A

### **Software Stack**

#### **Servidor**
- **OS**: Ubuntu 22.04 LTS
- **Python**: 3.11+
- **Deep Learning**: PyTorch 2.0+, Ultralytics YOLOv8
- **Inference**: TensorRT, ONNX Runtime  
- **Database**: PostgreSQL para logs, Redis para cache
- **API**: FastAPI para endpoints REST

#### **Edge Devices**
- **OS**: Raspberry Pi OS Lite (64-bit)
- **Python**: 3.11+ 
- **Inference**: TFLite, ONNX Runtime ARM
- **Camera**: OpenCV, PiCamera
- **Communication**: MQTT, HTTP requests

## ğŸ—ï¸ **ARQUITECTURA DETALLADA**

### **ETAPA A: DETECTOR YOLOv8-s**

#### **Objetivo**
Detectar regiones sospechosas de fuego/humo con **mÃ¡ximo recall** (no perder ningÃºn incendio real).

#### **Especificaciones**
```python
# ConfiguraciÃ³n del Detector
Model: YOLOv8-s
Input Size: 1440x808 (native camera format)
Classes: [fire, smoke] 
Batch Size: 20 (A100) / 8 (RTX 3090)
Inference Time: ~15ms per image (A100)
Confidence Threshold: 0.3 (bajo para alto recall)
NMS Threshold: 0.45
```

#### **Dataset de Entrenamiento**
- **Total**: 64,000 imÃ¡genes balanceadas
- **Fuentes**: FASDD, D-Fire, NEMO, PyroNear-2024, FigLib
- **Split**: 80% train / 20% validation
- **AugmentaciÃ³n**: Mosaic, MixUp, CutMix, HSV, Blur

#### **MÃ©tricas Objetivo**
- **Recall**: â‰¥95% (crÃ­tico - no perder incendios reales)
- **mAP@0.5**: â‰¥85%
- **Inference Speed**: <20ms por imagen
- **False Positive Rate**: ~40% (aceptable, serÃ¡ corregido por verificador)

#### **Salidas del Detector**
```python
detection_output = {
    'bounding_boxes': [(x1, y1, x2, y2), ...],
    'confidences': [0.85, 0.72, ...],
    'classes': ['fire', 'smoke', ...],
    'inference_time_ms': 15.2
}
```

### **ETAPA B: VERIFICADOR SmokeyNet-Lite**

#### **Objetivo**
Confirmar o rechazar detecciones del YOLOv8, reduciendo **falsos positivos en 70%+**.

#### **Especificaciones**
```python
# ConfiguraciÃ³n del Verificador
Model: SmokeyNet-Lite (EfficientNet-B0 + LSTM)
Input Size: 224x224 (crops de bounding boxes)
Classes: [true_detection, false_positive]
Batch Size: 64 (A100) / 32 (RTX 3090) 
Inference Time: ~5ms per crop (A100)
Confidence Threshold: 0.5
```

#### **Arquitectura del Verificador**
```python
class SmokeyNetLite(nn.Module):
    def __init__(self):
        # Backbone pre-entrenado
        self.backbone = EfficientNet-B0(pretrained=True)  # 1280 features
        
        # MÃ³dulo temporal (opcional)
        self.lstm = LSTM(1280, 256, bidirectional=True)  # 512 features
        
        # Clasificador binario
        self.classifier = Sequential(
            Linear(512, 256),
            ReLU(), Dropout(0.3),
            Linear(256, 64),
            ReLU(), Dropout(0.3), 
            Linear(64, 2)  # [true_detection, false_positive]
        )
```

#### **Dataset del Verificador**
```
Estructura del Dataset:
RNA/data/verificator_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/ (40,000 crops)
â”‚   â”‚   â”œâ”€â”€ true_fire/      (10,000 - 25%)
â”‚   â”‚   â”œâ”€â”€ true_smoke/     (10,000 - 25%) 
â”‚   â”‚   â””â”€â”€ false_positive/ (20,000 - 50%)
â”‚   â””â”€â”€ val/ (10,000 crops)
â”‚       â”œâ”€â”€ true_fire/      (2,500)
â”‚       â”œâ”€â”€ true_smoke/     (2,500)
â”‚       â””â”€â”€ false_positive/ (5,000)
```

#### **Estrategia de Falsos Positivos**
- **Nubes**: Detectadas como humo â†’ rechazar
- **Vapores**: Vapor agua, niebla â†’ rechazar  
- **Reflejos**: Reflejos solares â†’ rechazar
- **Polvo**: Polvo en movimiento â†’ rechazar
- **Objetos**: Chimeneas, estructuras â†’ rechazar

#### **MÃ©tricas Objetivo**
- **PrecisiÃ³n Sistema**: â‰¥85% (vs 60% solo detector)
- **ReducciÃ³n FP**: â‰¥70% 
- **RetenciÃ³n TP**: â‰¥95%
- **F1-Score**: â‰¥0.80
- **Inference Speed**: <10ms por crop

### **LÃ“GICA DE DECISIÃ“N COMBINADA**

```python
def sai_decision_engine(image):
    """
    Motor de decisiÃ³n SAI completo
    Combina Detector + Verificador para decisiÃ³n final
    """
    
    # ETAPA A: DetecciÃ³n
    detections = yolo_detector(image, conf_threshold=0.3)
    
    if not detections:
        return {
            'alert': False,
            'reason': 'No detections found',
            'confidence': 0.0
        }
    
    # ETAPA B: VerificaciÃ³n
    verified_detections = []
    
    for detection in detections:
        # Extraer crop de la detecciÃ³n
        crop = extract_crop(image, detection.bbox, padding=0.2)
        
        # Verificar con CNN
        verification_result = verificator_cnn(crop)
        
        # DecisiÃ³n por detecciÃ³n individual
        detector_conf = detection.confidence
        verificator_conf = verification_result.probability
        
        # Reglas de decisiÃ³n combinada
        if verificator_conf > 0.7:  # Alta confianza verificador
            verified_detections.append(detection)
        elif detector_conf > 0.8 and verificator_conf > 0.3:  # Alta det, media ver
            verified_detections.append(detection)
        elif detector_conf > 0.9:  # Muy alta confianza detector (bypass)
            verified_detections.append(detection)
        # Else: rechazar detecciÃ³n
    
    # DecisiÃ³n final del sistema
    if verified_detections:
        max_confidence = max(d.confidence for d in verified_detections)
        return {
            'alert': True,
            'detections_count': len(verified_detections),
            'max_confidence': max_confidence,
            'verified_detections': verified_detections,
            'reason': f'{len(verified_detections)} detection(s) verified'
        }
    else:
        return {
            'alert': False,
            'reason': 'All detections rejected by verificator',
            'rejected_count': len(detections)
        }
```

## âš¡ **PIPELINE DE INFERENCIA COMPLETO**

### **Modo Servidor (Centralizado)**
```python
# Pipeline optimizado para servidor con GPU
async def server_inference_pipeline(image_batch):
    """
    Pipeline de inferencia optimizado para servidor
    Procesa mÃºltiples imÃ¡genes en paralelo
    """
    
    # Batch processing del detector
    batch_detections = await yolo_detector.predict_batch(
        image_batch, 
        conf=0.3,
        batch_size=20
    )
    
    # Extraer todos los crops para verificaciÃ³n
    all_crops = []
    crop_metadata = []
    
    for img_idx, detections in enumerate(batch_detections):
        for det_idx, detection in enumerate(detections):
            crop = extract_crop(image_batch[img_idx], detection.bbox)
            all_crops.append(crop)
            crop_metadata.append({
                'image_idx': img_idx,
                'detection_idx': det_idx,
                'original_detection': detection
            })
    
    # Batch verification de todos los crops
    if all_crops:
        verification_results = await verificator_cnn.predict_batch(
            all_crops,
            batch_size=64
        )
        
        # Combinar resultados
        final_results = combine_results(
            crop_metadata, 
            verification_results
        )
    else:
        final_results = [{'alert': False}] * len(image_batch)
    
    return final_results

# Performance esperado:
# - 20 imÃ¡genes/batch en A100
# - ~400ms tiempo total por batch
# - ~20 imÃ¡genes/segundo throughput
```

### **Modo Edge (Distribuido)**
```python
# Pipeline simplificado para Raspberry Pi
def edge_inference_pipeline(image):
    """
    Pipeline liviano para edge devices
    Solo clasificaciÃ³n, detecciÃ³n en servidor
    """
    
    # Pre-filtro ligero local
    edge_classification = mobilenet_classifier(image)
    
    if edge_classification.probability > 0.4:  # Threshold conservativo
        # Enviar al servidor para procesamiento completo
        server_result = await send_to_server(image)
        return server_result
    else:
        return {'alert': False, 'source': 'edge_filter'}

# Performance esperado:
# - ~200ms por imagen en RPi 4
# - ReducciÃ³n 60-80% trÃ¡fico a servidor
# - AutonomÃ­a local para filtrado bÃ¡sico
```

## ğŸ“ˆ **MÃ‰TRICAS DE PERFORMANCE ESPERADAS**

### **MÃ©tricas del Sistema Completo**

#### **PrecisiÃ³n y Recall**
```
ConfiguraciÃ³n Actual (Solo Detector):
â”œâ”€â”€ Recall: 95% âœ… (excelente)
â”œâ”€â”€ Precision: 60% âš ï¸ (mejorable)
â”œâ”€â”€ F1-Score: 0.74
â””â”€â”€ False Positive Rate: 40%

ConfiguraciÃ³n Objetivo (Detector + Verificador):
â”œâ”€â”€ Recall: 92% âœ… (mantener alto)
â”œâ”€â”€ Precision: 85% âœ… (mejora +25 puntos)
â”œâ”€â”€ F1-Score: 0.88 âœ… (+0.14 mejora)
â””â”€â”€ False Positive Rate: 8% âœ… (-32 puntos)
```

#### **Latencia y Throughput**
```
Servidor A100:
â”œâ”€â”€ Detector: 15ms/imagen
â”œâ”€â”€ Verificador: 5ms/crop (promedio 2 crops/imagen)
â”œâ”€â”€ Latencia Total: ~25ms/imagen
â”œâ”€â”€ Throughput: 40 imÃ¡genes/segundo
â””â”€â”€ Capacidad: 144,000 imÃ¡genes/hora

Servidor RTX 3090:
â”œâ”€â”€ Detector: 25ms/imagen  
â”œâ”€â”€ Verificador: 8ms/crop
â”œâ”€â”€ Latencia Total: ~40ms/imagen
â”œâ”€â”€ Throughput: 25 imÃ¡genes/segundo
â””â”€â”€ Capacidad: 90,000 imÃ¡genes/hora

Edge (Raspberry Pi 4):
â”œâ”€â”€ Clasificador: 200ms/imagen
â”œâ”€â”€ Throughput: 5 imÃ¡genes/segundo
â”œâ”€â”€ Capacidad: 18,000 imÃ¡genes/hora
â””â”€â”€ TrÃ¡fico reducido: 70% menos envÃ­os
```

## ğŸš€ **PLAN DE IMPLEMENTACIÃ“N**

### **Fase 1: MVP Servidor (ACTUAL)**
- âœ… **Detector YOLOv8-s entrenado y desplegado**
- â³ **Verificador CNN en entrenamiento** 
- â³ **IntegraciÃ³n Detector + Verificador**
- â³ **Sistema de notificaciones bÃ¡sico**

### **Fase 2: OptimizaciÃ³n Servidor**
- ğŸ“‹ **OptimizaciÃ³n de throughput batch**
- ğŸ“‹ **Sistema de caching inteligente**  
- ğŸ“‹ **API REST completa**
- ğŸ“‹ **Dashboard de monitoreo**

### **Fase 3: Despliegue Edge** 
- ğŸ“‹ **Modelo edge optimizado (TFLite)**
- ğŸ“‹ **Sistema de comunicaciÃ³n MQTT**
- ğŸ“‹ **SincronizaciÃ³n automÃ¡tica**
- ğŸ“‹ **Monitoreo distribuido**

### **Fase 4: ProducciÃ³n Completa**
- ğŸ“‹ **Balanceador de carga multi-GPU**
- ğŸ“‹ **Sistema de alertas escalable**  
- ğŸ“‹ **Analytics y reportes**
- ğŸ“‹ **Mantenimiento automÃ¡tico**

## ğŸ› ï¸ **SCRIPTS DE DESPLIEGUE**

### **Script de Entrenamiento Completo**
```bash
#!/bin/bash
# train_sai_complete.sh - Entrena todo el sistema SAI

echo "ğŸ”¥ Entrenando Sistema SAI Completo"

# Etapa A: Detector (Si no estÃ¡ entrenado)
if [ ! -f "RNA/training/runs/sai_detector_training/weights/best.pt" ]; then
    echo "ğŸ¯ Entrenando Detector YOLOv8-s..."
    ./start_detector_training_optimized.sh
fi

# Crear dataset del verificador
echo "ğŸ“Š Creando dataset del verificador..."
python3 RNA/scripts/create_verificator_dataset.py \
    --yolo-dataset RNA/data/mega_fire_dataset \
    --output RNA/data/verificator_dataset

# Etapa B: Verificador  
echo "ğŸ” Entrenando Verificador CNN..."
python3 RNA/scripts/train_verificator.py \
    --dataset RNA/data/verificator_dataset \
    --output-dir RNA/training/runs/verificator \
    --gpu-optimized

echo "âœ… Sistema SAI entrenado completamente"
```

### **Script de Inferencia Integrada**
```python
#!/usr/bin/env python3
# sai_inference.py - Inferencia completa del sistema SAI

import torch
from ultralytics import YOLO
from RNA.scripts.train_verificator import SmokeyNetLite

class SAISystem:
    def __init__(self, detector_path, verificator_path):
        # Cargar modelos
        self.detector = YOLO(detector_path)
        
        # Cargar verificador
        checkpoint = torch.load(verificator_path)
        self.verificator = SmokeyNetLite(
            backbone=checkpoint['config']['backbone']
        )
        self.verificator.load_state_dict(checkpoint['model_state_dict'])
        self.verificator.eval()
        
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.verificator.to(self.device)
    
    def predict(self, image_path):
        """PredicciÃ³n completa SAI"""
        
        # Etapa A: Detectar
        results = self.detector(image_path, conf=0.3)
        
        if not results[0].boxes:
            return {'alert': False, 'reason': 'No detections'}
        
        # Etapa B: Verificar cada detecciÃ³n
        verified_detections = []
        
        for box in results[0].boxes:
            # Extraer crop
            crop = self.extract_crop(image_path, box)
            
            # Verificar
            with torch.no_grad():
                crop_tensor = self.preprocess_crop(crop)
                output = self.verificator(crop_tensor)
                prob = torch.softmax(output, dim=1)[0][0]  # true_detection prob
                
                if prob > 0.5:
                    verified_detections.append({
                        'bbox': box.xyxy[0].tolist(),
                        'confidence': float(box.conf[0]),
                        'verification_prob': float(prob),
                        'class': int(box.cls[0])
                    })
        
        # DecisiÃ³n final
        if verified_detections:
            return {
                'alert': True,
                'detections': verified_detections,
                'count': len(verified_detections)
            }
        else:
            return {
                'alert': False, 
                'reason': 'All detections rejected by verificator'
            }

if __name__ == "__main__":
    # Inicializar sistema
    sai = SAISystem(
        detector_path="RNA/training/runs/sai_detector_training/weights/best.pt",
        verificator_path="RNA/training/runs/verificator/verificator_best.pt"
    )
    
    # Predecir
    result = sai.predict("test_image.jpg")
    print(f"ğŸ”¥ SAI Result: {result}")
```

## ğŸ“Š **MONITOREO Y ANÃLISIS**

### **MÃ©tricas de ProducciÃ³n**
```python
# MÃ©tricas que se monitorean en producciÃ³n
production_metrics = {
    'performance': {
        'detector_inference_time_ms': [],
        'verificator_inference_time_ms': [],
        'total_pipeline_time_ms': [],
        'throughput_images_per_second': [],
        'gpu_utilization_percent': []
    },
    'accuracy': {
        'true_positives_count': 0,
        'false_positives_count': 0,
        'false_negatives_count': 0,
        'precision': 0.0,
        'recall': 0.0,
        'f1_score': 0.0
    },
    'system': {
        'memory_usage_gb': [],
        'cpu_usage_percent': [],
        'disk_usage_gb': [],
        'network_bandwidth_mbps': []
    }
}
```

### **Dashboard de Monitoreo**
- **Grafana** para visualizaciÃ³n de mÃ©tricas en tiempo real
- **Prometheus** para recolecciÃ³n de mÃ©tricas
- **Alertmanager** para notificaciones de sistema
- **Logs centralizados** con ELK Stack

## ğŸ”’ **CONSIDERACIONES DE SEGURIDAD**

### **Seguridad del Modelo**
- **EncriptaciÃ³n** de modelos en disco
- **AutenticaciÃ³n** para APIs de inferencia  
- **Rate limiting** para prevenir ataques
- **ValidaciÃ³n** de inputs para evitar adversarial attacks

### **Seguridad de Datos**
- **EncriptaciÃ³n** de comunicaciones (TLS 1.3)
- **AnonimizaciÃ³n** de metadatos de imÃ¡genes
- **Retention policies** para logs y datos
- **Backup** automÃ¡tico de modelos y configuraciones

## ğŸ¯ **OBJETIVOS DE RENDIMIENTO FINAL**

```
ğŸ† OBJETIVOS SAI SISTEMA COMPLETO
===================================

PrecisiÃ³n:
â”œâ”€â”€ Recall: â‰¥92% (mantener detecciÃ³n incendios reales)
â”œâ”€â”€ Precision: â‰¥85% (reducir falsos positivos crÃ­ticos)  
â”œâ”€â”€ F1-Score: â‰¥0.88 (balance Ã³ptimo)
â””â”€â”€ Uptime: â‰¥99.5% (alta disponibilidad)

Performance:
â”œâ”€â”€ Latencia: <50ms por imagen (servidor)
â”œâ”€â”€ Throughput: â‰¥25 img/s (RTX 3090) / â‰¥40 img/s (A100)
â”œâ”€â”€ Escalabilidad: 100+ cÃ¡maras simultÃ¡neas
â””â”€â”€ Eficiencia: <300W consumo total

OperaciÃ³n:
â”œâ”€â”€ Tiempo de respuesta: <2 minutos alerta
â”œâ”€â”€ Falsos positivos: <5 por dÃ­a por cÃ¡mara
â”œâ”€â”€ Mantenimiento: <4 horas/mes downtime
â””â”€â”€ Actualizaciones: Sin interruciÃ³n servicio
```

---

**ğŸ”¥ Esta arquitectura completa establece el framework tÃ©cnico para implementar el sistema SAI mÃ¡s avanzado de detecciÃ³n de incendios con IA, combinando mÃ¡xima precisiÃ³n con eficiencia operacional.**

## ğŸ“ **PRÃ“XIMOS PASOS INMEDIATOS**

1. **Completar entrenamiento detector A100** (en progreso - ~2 horas restantes)
2. **Crear dataset verificador** usando modelo entrenado
3. **Entrenar verificador CNN** (estimado 2-4 horas A100)
4. **Integrar ambos modelos** en pipeline unificado  
5. **Desplegar sistema completo** en servidor de producciÃ³n

**Estado Actual**: âœ… Detector 95% completo, Verificador 100% preparado para entrenar